{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imputing NaNs\n",
    "To impute the NaNs for Country and County I thought about doing something complicated like using a dictionary to match the city and region with the correct country and county. This could be done for a real dataset, but considering the task was to forecast sales, independant of region/city/county/country it seemed silly to waste a lot of time on this. So instead I just imputed missing_country and missing_county to these columns if there was no value.\n",
    "\n",
    "avg_price and total_products are more important to the overall calculation, so I took more care with these, especially total_products. avg_price is used to estimate the sales of the new Â£30-40 line and, when doing this, the NaNs are simply removed. However, for the forecasting, the overall average price was imputed. This field isn't used for forecasting anyway so really this is just a placeholder value.\n",
    "\n",
    "Imputing total_products was a little more involved. I realised that the order number must be less than the total products and we had the order number for all sales (including Mobile data). So I calculated the mean total_products per num_orders for the first month. Then I used a simple apply to make the missing total_products = num_orders * mean. This gave a good estimate of the total products sold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages, import pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "import pickle\n",
    "\n",
    "pd.options.display.max_seq_items = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openfile=open( r\"C:\\Users\\Joseph\\Documents\\Beamly\\TakeHomeTask\\beamly_case_study2.pickle\", \"rb\")\n",
    "df=pickle.load(openfile)\n",
    "openfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make the usual checks to the dataframe: shape, columns, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27091, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['date', 'avg_hour', 'min_hour', 'max_hour', 'device_name',\n",
       "       'productBand', 'avg_price', 'total_products', 'num_orders', 'city',\n",
       "       'region', 'County', 'Country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avg_hour</th>\n",
       "      <th>min_hour</th>\n",
       "      <th>max_hour</th>\n",
       "      <th>device_name</th>\n",
       "      <th>productBand</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_products</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>County</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>29.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Redbourn</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-05</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>Desktop and Laptop</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>27.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>27.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>lessThan10</td>\n",
       "      <td>9.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Desktop and Laptop</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>29.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenwich</td>\n",
       "      <td>Greenwich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  avg_hour  min_hour  max_hour         device_name  \\\n",
       "1  2018-07-12      20.0        20        20              Mobile   \n",
       "2  2018-08-05      22.0        22        22  Desktop and Laptop   \n",
       "3  2018-07-13      14.0        14        14              Mobile   \n",
       "5  2018-08-10      19.0        19        19              Tablet   \n",
       "6  2018-07-12      17.0        17        17  Desktop and Laptop   \n",
       "\n",
       "      productBand  avg_price  total_products  num_orders       city  \\\n",
       "1  between20and30      29.95             1.0           1   Redbourn   \n",
       "2  between20and30      27.95             1.0           1   Bearsden   \n",
       "3  between20and30      27.95             1.0           1   Bearsden   \n",
       "5      lessThan10       9.95             1.0           1   Bearsden   \n",
       "6  between20and30      29.95             1.0           1  Greenwich   \n",
       "\n",
       "                region         County  Country  \n",
       "1        Hertfordshire  Hertfordshire  England  \n",
       "2  East Dunbartonshire            NaN      NaN  \n",
       "3  East Dunbartonshire            NaN      NaN  \n",
       "5  East Dunbartonshire            NaN      NaN  \n",
       "6            Greenwich            NaN      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on Nans\n",
    "\n",
    "Nans exist in the following columns and need to be imputed: avg_price, total_products, County, Country\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Start with something 'easy' or not too important. Want to think about how could impute Country/County, so look to see if city or region can help."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Country/County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I want to look at what different countries and counties there are. Originally I was wondering if I could cross-correlate them, and use county to fill in country and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'England': array(['Hertfordshire', 'Suffolk', 'Worcestershire', 'West Sussex',\n",
       "        'Lincolnshire', 'Essex', 'North Yorkshire', 'Cornwall', 'Devon',\n",
       "        'Norfolk', 'Hampshire', 'Buckinghamshire', 'Nottinghamshire',\n",
       "        'East Sussex', 'Kent', 'Lancashire', 'Staffordshire', 'Bristol',\n",
       "        'Surrey', 'Cumbria', 'Northumberland', 'Derbyshire',\n",
       "        'Northamptonshire', 'Gloucestershire', 'Cambridgeshire',\n",
       "        'Oxfordshire', 'Warwickshire', 'Somerset', 'Wiltshire', 'Dorset',\n",
       "        'Shropshire', 'Bedfordshire', 'Leicestershire', 'Herefordshire',\n",
       "        'Rutland'], dtype=object),\n",
       " 'Scotland': array(['Falkirk', 'East Lothian', 'Fife', 'Clackmannanshire', 'Moray',\n",
       "        'West Lothian', 'Scottish Borders', 'Aberdeenshire', 'Angus'],\n",
       "       dtype=object),\n",
       " 'Wales': array(['Pembrokeshire', 'Conwy', 'Monmouthshire', 'Carmarthenshire',\n",
       "        'Gwynedd', 'Denbighshire', 'Ceredigion', 'Wrexham', 'Flintshire',\n",
       "        'Powys'], dtype=object)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['Country'])['County'].unique().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_city_dict=df.groupby(['Country'])['city'].unique().to_dict()\n",
    "for i in country_city_dict['England']:\n",
    "    if i=='Greenwich':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was thinking of using the city and region to impute a county and country, but looks like that won't work as the country and county are missing together. \n",
    "\n",
    "I think the easiest thing to do now would be to replace the missing fields with missing_country and missing_county. Especially as it is not relevant to the problem, which is just to forecast sales, with no specific to country or county."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputing county/country\n",
    "use \"pd.notnull(x)==True else 'missing_country'\" to reassign the value of the country or county to missing_X if there is currently no value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e['Country']=df['Country'].apply(lambda x: x if pd.notnull(x)==True else 'missing_country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_e['County']=df['County'].apply(lambda x: x if pd.notnull(x)==True else 'missing_county')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avg_hour</th>\n",
       "      <th>min_hour</th>\n",
       "      <th>max_hour</th>\n",
       "      <th>device_name</th>\n",
       "      <th>productBand</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_products</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>County</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>29.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Redbourn</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-05</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>Desktop and Laptop</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>27.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>27.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>lessThan10</td>\n",
       "      <td>9.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Desktop and Laptop</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>29.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenwich</td>\n",
       "      <td>Greenwich</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  avg_hour  min_hour  max_hour         device_name  \\\n",
       "1  2018-07-12      20.0        20        20              Mobile   \n",
       "2  2018-08-05      22.0        22        22  Desktop and Laptop   \n",
       "3  2018-07-13      14.0        14        14              Mobile   \n",
       "5  2018-08-10      19.0        19        19              Tablet   \n",
       "6  2018-07-12      17.0        17        17  Desktop and Laptop   \n",
       "\n",
       "      productBand  avg_price  total_products  num_orders       city  \\\n",
       "1  between20and30      29.95             1.0           1   Redbourn   \n",
       "2  between20and30      27.95             1.0           1   Bearsden   \n",
       "3  between20and30      27.95             1.0           1   Bearsden   \n",
       "5      lessThan10       9.95             1.0           1   Bearsden   \n",
       "6  between20and30      29.95             1.0           1  Greenwich   \n",
       "\n",
       "                region          County          Country  \n",
       "1        Hertfordshire   Hertfordshire          England  \n",
       "2  East Dunbartonshire  missing_county  missing_country  \n",
       "3  East Dunbartonshire  missing_county  missing_country  \n",
       "5  East Dunbartonshire  missing_county  missing_country  \n",
       "6            Greenwich  missing_county  missing_country  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So nans are now imputed for the two easy ones, now need to do the harder ones. avg_price and total_products and band. Should probably do total products first, becuase that looks a litle easier. First will check if there are any nans at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing for avg_price and total_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the avg_price and total_products seem related, so I was wondering if it was possible to use one to impute the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n",
      "False False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_nans_in_two_columns(row):\n",
    "    if pd.notnull(row['avg_price']) or pd.notnull(row['total_products']):\n",
    "        \n",
    "        return 0\n",
    "    else:\n",
    "        print(pd.notnull(row['avg_price']),pd.notnull(row['total_products']))\n",
    "        return 1\n",
    "sum(df.apply(lambda row:check_nans_in_two_columns(row),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 6 at the same time, I just cut those out. However it seems a shame to loose data and also, looking at the header of the dataframe (above), I've noticed that the order number seems to always be larger than the total products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focusing on total products, I think total_products and order num orders are related, where total_products>order_number always. But will check this with the following function and apply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_orderno_totprod_relationship(row):\n",
    "    \"\"\"\n",
    "    checks to see if the total_products is larger than the order_number\n",
    "    \"\"\"\n",
    "    if row['total_products']>=row['num_orders'] or pd.notnull(row['total_products'])==False:\n",
    "        return 0\n",
    "    else:\n",
    "        print(row['total_products'],row['num_orders'])\n",
    "        return 1\n",
    "sum(df.apply(lambda row:check_orderno_totprod_relationship(row),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so I'm right about this relationship, so I will base this imputation on the order number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find the mean relation between order_number and total products, need dataframe without nans in the total product row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tp_noNaNs = df[np.isfinite(df['total_products'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find the mean difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_orderno_totprod_relationship(row):\n",
    "    return row['total_products']/row['num_orders']\n",
    "tot_product_imputation=np.mean(df_tp_noNaNs.apply(lambda row:calc_orderno_totprod_relationship(row),axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can now impute this value. Note that need to add +0.5 so that when I use int() the value is rounded up and not down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avg_hour</th>\n",
       "      <th>min_hour</th>\n",
       "      <th>max_hour</th>\n",
       "      <th>device_name</th>\n",
       "      <th>productBand</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_products</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>County</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>29.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Redbourn</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-05</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>Desktop and Laptop</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>27.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>27.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>lessThan10</td>\n",
       "      <td>9.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Desktop and Laptop</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>29.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenwich</td>\n",
       "      <td>Greenwich</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  avg_hour  min_hour  max_hour         device_name  \\\n",
       "1  2018-07-12      20.0        20        20              Mobile   \n",
       "2  2018-08-05      22.0        22        22  Desktop and Laptop   \n",
       "3  2018-07-13      14.0        14        14              Mobile   \n",
       "5  2018-08-10      19.0        19        19              Tablet   \n",
       "6  2018-07-12      17.0        17        17  Desktop and Laptop   \n",
       "\n",
       "      productBand  avg_price  total_products  num_orders       city  \\\n",
       "1  between20and30      29.95             1.0           1   Redbourn   \n",
       "2  between20and30      27.95             1.0           1   Bearsden   \n",
       "3  between20and30      27.95             1.0           1   Bearsden   \n",
       "5      lessThan10       9.95             1.0           1   Bearsden   \n",
       "6  between20and30      29.95             1.0           1  Greenwich   \n",
       "\n",
       "                region          County          Country  \n",
       "1        Hertfordshire   Hertfordshire          England  \n",
       "2  East Dunbartonshire  missing_county  missing_country  \n",
       "3  East Dunbartonshire  missing_county  missing_country  \n",
       "5  East Dunbartonshire  missing_county  missing_country  \n",
       "6            Greenwich  missing_county  missing_country  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def impute_tp(row):\n",
    "    if pd.notnull(row['total_products'])==False:\n",
    "        return int(row['num_orders']*tot_product_imputation+0.5)#+0.5 is to round up instead of down\n",
    "    else:\n",
    "        return row['total_products']\n",
    "df_e['total_products']=df.apply(lambda row: impute_tp(row),axis=1)\n",
    "df_e.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new dataframe looks good, check the histogram as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22870a21b38>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e['total_products'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks good to me, now for the harder bit, imputing the data for avg_price. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing avg_price\n",
    "Look at the NaN data for avg_price a bit first. I am wondering if there is a clever solution, but I may have to impute the mean avg_price. Make two new dataframes for this check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap_NaNs=df[np.isfinite(df['avg_price'])==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ap_noNaNs=df[np.isfinite(df['avg_price'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many NaNs are there, instead of avg_price, on each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_hour</th>\n",
       "      <th>min_hour</th>\n",
       "      <th>max_hour</th>\n",
       "      <th>device_name</th>\n",
       "      <th>productBand</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_products</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>County</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-01</th>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-02</th>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-03</th>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04</th>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-05</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-06</th>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-07</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-08</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-09</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-10</th>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-11</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-12</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-13</th>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-14</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-15</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-16</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-17</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-18</th>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-19</th>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-20</th>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-21</th>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-22</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-23</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-24</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-25</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-26</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-27</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-28</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-29</th>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-30</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-31</th>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-03</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-04</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-05</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-06</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-07</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-08</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-09</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-10</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-13</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            avg_hour  min_hour  max_hour  device_name  productBand  avg_price  \\\n",
       "date                                                                            \n",
       "2018-07-01        41        41        41           41           41          0   \n",
       "2018-07-02        55        55        55           55           55          0   \n",
       "2018-07-03        51        51        51           51           51          0   \n",
       "2018-07-04        47        47        47           47           47          0   \n",
       "2018-07-05        49        49        49           49           49          0   \n",
       "2018-07-06        45        45        45           45           45          0   \n",
       "2018-07-07        18        18        18           18           18          0   \n",
       "2018-07-08        20        20        20           20           20          0   \n",
       "2018-07-09        35        35        35           35           35          0   \n",
       "2018-07-10        39        39        39           39           39          0   \n",
       "2018-07-11        23        23        23           23           23          0   \n",
       "2018-07-12        36        36        36           36           36          0   \n",
       "2018-07-13        27        27        27           27           27          0   \n",
       "2018-07-14        34        34        34           34           34          0   \n",
       "2018-07-15        29        29        29           29           29          0   \n",
       "2018-07-16        23        23        23           23           23          0   \n",
       "2018-07-17        24        24        24           24           24          0   \n",
       "2018-07-18        70        70        70           70           70          0   \n",
       "2018-07-19        80        80        80           80           80          0   \n",
       "2018-07-20        61        61        61           61           61          0   \n",
       "2018-07-21        44        44        44           44           44          0   \n",
       "2018-07-22        31        31        31           31           31          0   \n",
       "2018-07-23        38        38        38           38           38          0   \n",
       "2018-07-24        48        48        48           48           48          0   \n",
       "2018-07-25        28        28        28           28           28          0   \n",
       "2018-07-26        26        26        26           26           26          0   \n",
       "2018-07-27        22        22        22           22           22          0   \n",
       "2018-07-28        25        25        25           25           25          0   \n",
       "2018-07-29        33        33        33           33           33          0   \n",
       "2018-07-30        25        25        25           25           25          0   \n",
       "2018-07-31        31        31        31           31           31          0   \n",
       "2018-08-01        12        12        12           12           12          0   \n",
       "2018-08-02        14        14        14           14           14          0   \n",
       "2018-08-03        14        14        14           14           14          0   \n",
       "2018-08-04         9         9         9            9            9          0   \n",
       "2018-08-05         4         4         4            4            4          0   \n",
       "2018-08-06         5         5         5            5            5          0   \n",
       "2018-08-07         6         6         6            6            6          0   \n",
       "2018-08-08         3         3         3            3            3          0   \n",
       "2018-08-09         2         2         2            2            2          0   \n",
       "2018-08-10         3         3         3            3            3          0   \n",
       "2018-08-11         1         1         1            1            1          0   \n",
       "2018-08-12         2         2         2            2            2          0   \n",
       "2018-08-13         5         5         5            5            5          0   \n",
       "\n",
       "            total_products  num_orders  city  region  County  Country  \n",
       "date                                                                   \n",
       "2018-07-01              41          41    41      41      41       41  \n",
       "2018-07-02              55          55    55      55      55       55  \n",
       "2018-07-03              51          51    51      51      51       51  \n",
       "2018-07-04              47          47    47      47      47       47  \n",
       "2018-07-05              49          49    49      49      49       49  \n",
       "2018-07-06              45          45    45      45      45       45  \n",
       "2018-07-07              18          18    18      18      18       18  \n",
       "2018-07-08              20          20    20      20      20       20  \n",
       "2018-07-09              35          35    35      35      35       35  \n",
       "2018-07-10              39          39    39      39      39       39  \n",
       "2018-07-11              23          23    23      23      23       23  \n",
       "2018-07-12              36          36    36      36      36       36  \n",
       "2018-07-13              27          27    27      27      27       27  \n",
       "2018-07-14              34          34    34      34      34       34  \n",
       "2018-07-15              29          29    29      29      29       29  \n",
       "2018-07-16              23          23    23      23      23       23  \n",
       "2018-07-17              24          24    24      24      24       24  \n",
       "2018-07-18              70          70    70      70      70       70  \n",
       "2018-07-19              80          80    80      80      80       80  \n",
       "2018-07-20              61          61    61      61      61       61  \n",
       "2018-07-21              44          44    44      44      44       44  \n",
       "2018-07-22              31          31    31      31      31       31  \n",
       "2018-07-23              38          38    38      38      38       38  \n",
       "2018-07-24              48          48    48      48      48       48  \n",
       "2018-07-25              28          28    28      28      28       28  \n",
       "2018-07-26              26          26    26      26      26       26  \n",
       "2018-07-27              22          22    22      22      22       22  \n",
       "2018-07-28              25          25    25      25      25       25  \n",
       "2018-07-29              33          33    33      33      33       33  \n",
       "2018-07-30              25          25    25      25      25       25  \n",
       "2018-07-31              31          31    31      31      31       31  \n",
       "2018-08-01              12          12    12      12      12       12  \n",
       "2018-08-02              14          14    14      14      14       14  \n",
       "2018-08-03              14          14    14      14      14       14  \n",
       "2018-08-04               9           9     9       9       9        9  \n",
       "2018-08-05               4           4     4       4       4        4  \n",
       "2018-08-06               5           5     5       5       5        5  \n",
       "2018-08-07               6           6     6       6       6        6  \n",
       "2018-08-08               3           3     3       3       3        3  \n",
       "2018-08-09               2           2     2       2       2        2  \n",
       "2018-08-10               3           3     3       3       3        3  \n",
       "2018-08-11               1           1     1       1       1        1  \n",
       "2018-08-12               2           2     2       2       2        2  \n",
       "2018-08-13               5           5     5       5       5        5  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ap_NaNs.sort_values(['date']).groupby(['date']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NaNs are evenly spread over the time period, except the end two weeks, but this is obviously not including mobile data. It's tempting to just drop these rows, but considering we are trying to forcast number of sales and not amount of sales, it shouldn't affect the results to impute something such as the mean. However if we wanted to forecast turnover then we shold really drop these rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute the mean avg_price for the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avg_hour</th>\n",
       "      <th>min_hour</th>\n",
       "      <th>max_hour</th>\n",
       "      <th>device_name</th>\n",
       "      <th>productBand</th>\n",
       "      <th>avg_price</th>\n",
       "      <th>total_products</th>\n",
       "      <th>num_orders</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>County</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>29.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Redbourn</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>Hertfordshire</td>\n",
       "      <td>England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-05</td>\n",
       "      <td>22.0</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>Desktop and Laptop</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>27.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>27.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>lessThan10</td>\n",
       "      <td>9.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bearsden</td>\n",
       "      <td>East Dunbartonshire</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>Desktop and Laptop</td>\n",
       "      <td>between20and30</td>\n",
       "      <td>29.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenwich</td>\n",
       "      <td>Greenwich</td>\n",
       "      <td>missing_county</td>\n",
       "      <td>missing_country</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  avg_hour  min_hour  max_hour         device_name  \\\n",
       "1  2018-07-12      20.0        20        20              Mobile   \n",
       "2  2018-08-05      22.0        22        22  Desktop and Laptop   \n",
       "3  2018-07-13      14.0        14        14              Mobile   \n",
       "5  2018-08-10      19.0        19        19              Tablet   \n",
       "6  2018-07-12      17.0        17        17  Desktop and Laptop   \n",
       "\n",
       "      productBand  avg_price  total_products  num_orders       city  \\\n",
       "1  between20and30      29.95             1.0           1   Redbourn   \n",
       "2  between20and30      27.95             1.0           1   Bearsden   \n",
       "3  between20and30      27.95             1.0           1   Bearsden   \n",
       "5      lessThan10       9.95             1.0           1   Bearsden   \n",
       "6  between20and30      29.95             1.0           1  Greenwich   \n",
       "\n",
       "                region          County          Country  \n",
       "1        Hertfordshire   Hertfordshire          England  \n",
       "2  East Dunbartonshire  missing_county  missing_country  \n",
       "3  East Dunbartonshire  missing_county  missing_country  \n",
       "5  East Dunbartonshire  missing_county  missing_country  \n",
       "6            Greenwich  missing_county  missing_country  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def impute_ap(row):\n",
    "    if pd.notnull(row['avg_price'])==False:\n",
    "        return df_ap_noNaNs['avg_price'].mean()\n",
    "    else:\n",
    "        return row['avg_price']\n",
    "df_e['avg_price']=df.apply(lambda row: impute_ap(row),axis=1)\n",
    "df_e.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Imputation has worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date              False\n",
       "avg_hour          False\n",
       "min_hour          False\n",
       "max_hour          False\n",
       "device_name       False\n",
       "productBand       False\n",
       "avg_price         False\n",
       "total_products    False\n",
       "num_orders        False\n",
       "city              False\n",
       "region            False\n",
       "County            False\n",
       "Country           False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_e.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay, no more NaNs in any columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save file as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filehandler = open(r\"C:\\Users\\Joseph\\Documents\\Beamly\\TakeHomeTask\\beamly_case_study_noNaNs.pickle\",\"wb\")\n",
    "pickle.dump(df_e,filehandler)\n",
    "filehandler.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
